High=factor(ifelse(Sales<=8,"No","Yes"))
Carseats=data.frame(Carseats,High)
tree.carseats=tree(High~.-Sales,Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.carseats
set.seed(2)
train=sample(1:nrow(Carseats), 200)
Carseats.test=Carseats[-train,]
High.test=High[-train]
tree.carseats=tree(High~.-Sales,Carseats,subset=train)
tree.pred=predict(tree.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(104+50)/200
set.seed(3)
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow=c(1,2))
plot(cv.carseats$size,cv.carseats$dev,type="b")
plot(cv.carseats$k,cv.carseats$dev,type="b")
prune.carseats=prune.misclass(tree.carseats,best=9)
plot(prune.carseats)
text(prune.carseats,pretty=0)
tree.pred=predict(prune.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(97+58)/200
prune.carseats=prune.misclass(tree.carseats,best=15)
plot(prune.carseats)
text(prune.carseats,pretty=0)
tree.pred=predict(prune.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(102+53)/200
library(MASS)
set.seed(1)
dim(Boston)
#?Boston
train = sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston=tree(medv~.,Boston,subset=train)
summary(tree.boston)
plot(tree.boston)
text(tree.boston,pretty=0)
cv.boston=cv.tree(tree.boston)
plot(cv.boston$size,cv.boston$dev,type='b')
prune.boston=prune.tree(tree.boston,best=5)
plot(prune.boston)
text(prune.boston,pretty=0)
yhat=predict(tree.boston,newdata=Boston[-train,])
boston.test=Boston[-train,"medv"]
plot(yhat,boston.test)
abline(0,1)
mean((yhat-boston.test)^2)
library(randomForest)
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)/2)
rf.boston=randomForest(medv~.,data=Boston,subset=train,importance=TRUE)
rf.boston
obb.err=double(13)
test.err=double(13)
for(mtry in 1:13){
fit=randomForest(medv~.,data=Boston,subset=train,mtry=mtry,ntree=400)
obb.err[mtry]=fit$mse[400]
pred=predict(fit,Boston[-train,])
test.err[mtry]=with(Boston[-train,],mean((medv-pred)^2))
cat(mtry," ")
}
matplot(1:mtry,cbind(test.err,obb.err),pch = 19,col = c("red","blue"),type = "b",ylab = "Mean squared errors")
legend("topright",legend = c("Test","OOB"),pch = 19,col = c("red","blue"))
#
set.seed(1)
bag.boston=randomForest(medv~.,data=Boston,subset=train,mtry=13,importance=TRUE)
bag.boston
yhat.bag = predict(bag.boston,newdata=Boston[-train,])
plot(yhat.bag, boston.test)
abline(0,1)
mean((yhat.bag-boston.test)^2)
bag.boston=randomForest(medv~.,data=Boston,subset=train,mtry=13,ntree=25)
bag.boston
yhat.bag = predict(bag.boston,newdata=Boston[-train,])
mean((yhat.bag-boston.test)^2)
rf.boston=randomForest(medv~.,data=Boston,subset=train,mtry=6,importance=TRUE)
rf.boston
yhat.rf = predict(rf.boston,newdata=Boston[-train,])
mean((yhat.rf-boston.test)^2)
importance(rf.boston)
varImpPlot(rf.boston)
library(gbm)
set.seed(1)
boost.boston.v=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=10000,shrinkage = 0.01,interaction.depth=4) #4 split per tree; tree shrinkage degree
summary(boost.boston.v)
plot(boost.boston.v,i="lstat")
plot(boost.boston.v,i="rm")
set.seed(1)
boost.boston=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=5000,interaction.depth=4)
summary(boost.boston)
par(mfrow=c(1,2))
plot(boost.boston,i="rm")
plot(boost.boston,i="lstat")
yhat.boost=predict(boost.boston,newdata=Boston[-train,],n.trees=5000)
mean((yhat.boost-boston.test)^2)
boost.boston=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=5000,interaction.depth=4,shrinkage=0.2,verbose=F)
yhat.boost=predict(boost.boston,newdata=Boston[-train,],n.trees=5000)
mean((yhat.boost-boston.test)^2)
set.seed(1)
n.trees=seq(from=100,to=10000,by=100)
predmat=predict(boost.boston,newdata=Boston[-train,],n.trees=n.trees)
dim(predmat)
berr=with(Boston[-train,],apply((predmat-medv)^2,2,mean))
plot(n.trees,berr,pch=19,ylab = "Mean squared errors",xlab = "# Trees",main =" Bossting Test Error")
abline(h=min(test.err),col="red")
matplot(1:mtry,cbind(test.err,obb.err),pch = 19,col = c("red","blue"),type = "b",ylab = "Mean squared errors")
legend("topright",legend = c("Test","OOB"),pch = 19,col = c("red","blue"))
abline(h=min(test.err),col="red")
library(ISLR)
summary(OJ)
set.seed(10)
train=sample(1:nrow(OJ), 800)
OJ.test=OJ[-train,]
OJ.train=OJ[train,]
summary(OJ.test)
summary(OJ.train)
dim(OJ)
dim(OJ.test)
dim(OJ.train)
tree.OJ=tree(Purchase~.,OJ,subset=train)
summary(tree.OJ)
tree.OJ
?OJ
plot(tree.OJ);text(tree.OJ,pretty=0)
tree.pred=predict(tree.OJ,OJ.test,type="class")
purchase.test=OJ.test$Purchase
table(tree.pred,purchase.test)
(135+88)/270
1-((135+88)/270)
cv.OJ=cv.tree(tree.OJ,FUN=prune.misclass)
names(cv.OJ)
cv.OJ
plot(cv.OJ)
plot(cv.OJ$size,cv.OJ$dev,type="b")
prune.OJ=prune.misclass(tree.OJ,best=5)
plot(prune.OJ);text(prune.OJ,pretty=0)
summary(tree.OJ)
summary(prune.OJ)
tree.pred=predict(tree.OJ,OJ.test,type="class")
table(tree.pred,purchase.test)
(155+66)/270
1-((155+66)/270)
prune.pred=predict(prune.OJ,OJ.test,type="class")
table(prune.pred,purchase.test)
(151+68)/270
1-((151+68)/270)
library(ISLR)
summary(Hitters)
new.Hitters=na.omit(Hitters)
summary(new.Hitters)
logSalary=log(new.Hitters$Salary)
new.Hitters2=data.frame(new.Hitters,logSalary)
summary(new.Hitters2)
dim(new.Hitters2)
new.hitters.train=new.Hitters2[1:200,]
new.hitters.test=new.Hitters2[201:nrow(new.Hitters2),]
dim(new.hitters.train)
dim(new.hitters.test)
library(gbm)
shrinkage=seq(0.001,0.2,0.001)
train.err=double(200)
test.err=double(200)
for(s in shrinkage){
boost.hitters=gbm(logSalary~.-Salary, data=new.hitters.train, distribution="gaussian", n.trees=1000, shrinkage=s)
yhat.boost=predict(boost.hitters, newdata=new.hitters.test, n.trees=1000)
train.err[s*1000] <- mean((boost.hitters$train.error)^2)
test.err[s*1000] <- mean((yhat.boost-new.hitters.test$logSalary)^2)
}
plot(data.frame(shrinkage,train.err),type = "b",ylab = "Mean squared errors")
plot(data.frame(shrinkage,test.err),type = "l",ylab = "Mean squared errors")
set.seed(1)
boost.hitters=gbm(logSalary~.-Salary, data=new.hitters.train, distribution="gaussian", n.trees=1000, shrinkage=0.01)
yhat.boost <- predict(boost.hitters, newdata=new.hitters.test, n.trees = 1000)
mean((yhat.boost - new.hitters.test$logSalary)^2)
hitters.lm=lm(logSalary ~ .-Salary, data=new.hitters.train)
yhat.lm=predict(hitters.lm, newdata=new.hitters.test)
mean((yhat.lm - new.hitters.test$logSalary)^2)
summary(boost.hitters)
library(randomForest)
dim(new.hitters.train)
bag.hitters=randomForest(logSalary~.-Salary, data=new.hitters.train, mtry = 19, importance = TRUE)
yhat.bag=predict(bag.hitters, newdata=new.hitters.test)
mean((yhat.bag-new.hitters.test$logSalary)^2)
importance(bag.hitters)
varImpPlot(bag.hitters)
summary(Caravan)
dim(Caravan)
?ifelse
Caravan$Purchase=ifelse(Caravan$Purchase == "Yes", 1, 0)
Caravan.train=Caravan[1:1000,]
Caravan.test=Caravan[1001:nrow(Caravan),]
dim(Caravan.train)
dim(Caravan.test)
set.seed(1)
boost.Caravan=gbm(Purchase~.,data=Caravan.train,distribution="bernoulli",shrinkage=0.01,n.trees = 1000)
summary(boost.Caravan)
preds.boost=predict(boost.Caravan,newdata=Caravan.test,n.trees = 1000,type = "response")
preds.boost=ifelse(preds.boost > 0.2, "yes", "no")
table(Caravan.test$Purchase, preds.boost)
(4410+33)/4822
33/(123+33)
#logistic regression
Caravan.logi=glm(Purchase~ ., data = Caravan.train, family = "binomial")
preds.logi=predict(Caravan.logi, newdata=Caravan.test, type = "response")
preds.logi=ifelse(preds.logi > .2, "yes", "no")
table(Caravan.test$Purchase, preds.logi)
(4183+58)/4822
58/(350+58)
install.packages("remotes")
remotes::install_github("rundel/livecode")
s <- livecode::serve_file()
remotes::install_github("rundel/livecode")
remotes::install_github("rundel/livecode")
install.packages("remotes")
remotes::install_github("rundel/livecode")
s <- livecode::serve_file()
install.packages("remotes")
remotes::install_github("rundel/livecode")
s <- livecode::serve_file()
library(edgeR)
library(limma)
library(Glimma)
install.packages("Glimma")
library(Rsubread)
library(Glimma)
install.packages("Rsubread")
install.packages("keras")
install.packages("reticulate")
library(keras)
library(reticulate)
conda_create(packages="python=3.6")
use_condaenv("r-reticulate")
install_keras(method="conda", envname="r-reticulate")
library(keras)
library(reticulate)
use_condaenv("r-reticulate")
mnist <- dataset_mnist()
library(tensorflow)
tf_config()
library(reticulate)
reticulate::py_config()
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
# rescale
x_train <- x_train / 255
x_test <- x_test / 255
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 10, activation = 'softmax')
summary(model)
setwd("D:/R club/Deep_learning/Deep_Learning_MinYaoJhu")
library(keras)
reuters <- dataset_reuters(num_words = 10000)
c(c(train_data, train_labels), c(test_data, test_labels)) %<-% reuters
length(train_data)
length(test_data)
train_data[[1]]
word_index <- dataset_reuters_word_index()
reverse_word_index <- names(word_index)
names(reverse_word_index) <- word_index
decoded_newswire <- sapply(train_data[[1]], function(index) {
word <- if (index >= 3) reverse_word_index[[as.character(index - 3)]]
if (!is.null(word)) word else "?"
})
train_labels[[1]]
vectorize_sequences <- function(sequences, dimension = 10000) {
results <- matrix(0, nrow = length(sequences), ncol = dimension)
for (i in 1:length(sequences))
results[i, sequences[[i]]] <- 1
results
}
x_train <- vectorize_sequences(train_data)
x_test <- vectorize_sequences(test_data)
to_one_hot <- function(labels, dimension = 46) {
results <- matrix(0, nrow = length(labels), ncol = dimension)
for (i in 1:length(labels))
results[i, labels[[i]] + 1] <- 1
results
}
one_hot_train_labels <- to_one_hot(train_labels)
one_hot_test_labels <- to_one_hot(test_labels)
one_hot_train_labels <- to_categorical(train_labels)
one_hot_test_labels <- to_categorical(test_labels)
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 46, activation = "softmax")
model %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
val_indices <- 1:1000
x_val <- x_train[val_indices,]
partial_x_train <- x_train[-val_indices,]
y_val <- one_hot_train_labels[val_indices,]
partial_y_train = one_hot_train_labels[-val_indices,]
history <- model %>% fit(
partial_x_train,
partial_y_train,
epochs = 20,
batch_size = 512,
validation_data = list(x_val, y_val)
)
plot(history)
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 46, activation = "softmax")
model %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
history <- model %>% fit(
partial_x_train,
partial_y_train,
epochs = 9,
batch_size = 512,
validation_data = list(x_val, y_val)
)
results <- model %>% evaluate(x_test, one_hot_test_labels)
results
test_labels_copy <- test_labels
test_labels_copy <- sample(test_labels_copy)
length(which(test_labels == test_labels_copy)) / length(test_labels)
predictions <- model %>% predict(x_test)
dim(predictions)
sum(predictions[1,])
which.max(predictions[1,])
model %>% compile(
optimizer = "rmsprop",
loss = "sparse_categorical_crossentropy",
metrics = c("accuracy")
)
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu", input_shape = c(10000)) %>%
layer_dense(units = 4, activation = "relu") %>%
layer_dense(units = 46, activation = "softmax")
model %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
model %>% fit(
partial_x_train,
partial_y_train,
epochs = 20,
batch_size = 128,
validation_data = list(x_val, y_val)
)
library(keras)
dataset <- dataset_boston_housing()
c(c(train_data, train_targets), c(test_data, test_targets)) %<-% dataset
str(train_data)
str(test_data)
str(train_targets)
mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
train_data <- scale(train_data, center = mean, scale = std)
test_data <- scale(test_data, center = mean, scale = std)
build_model <- function() {
model <- keras_model_sequential() %>%
layer_dense(units = 64, activation = "relu",
input_shape = dim(train_data)[[2]]) %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 1)
model %>% compile(
optimizer = "rmsprop",
loss = "mse",
metrics = c("mae")
)
}
k <- 4
indices <- sample(1:nrow(train_data))
folds <- cut(indices, breaks = k, labels = FALSE)
num_epochs <- 100
all_scores <- c()
for (i in 1:k) {
cat("processing fold #", i, "\n")
val_indices <- which(folds == i, arr.ind = TRUE)                     #1
val_data <- train_data[val_indices,]
val_targets <- train_targets[val_indices]
partial_train_data <- train_data[-val_indices,]                      #2
partial_train_targets <- train_targets[-val_indices]
model <- build_model()                                               #3
model %>% fit(partial_train_data, partial_train_targets,             #4
epochs = num_epochs, batch_size = 1, verbose = 0)
results <- model %>% evaluate(val_data, val_targets, verbose = 0)    #5
all_scores <- c(all_scores, results$mean_absolute_error)
}
head(results)
all_scores <- c(all_scores, results$mae)
k <- 4
indices <- sample(1:nrow(train_data))
folds <- cut(indices, breaks = k, labels = FALSE)
num_epochs <- 100
all_scores <- c()
for (i in 1:k) {
cat("processing fold #", i, "\n")
val_indices <- which(folds == i, arr.ind = TRUE)                     #1
val_data <- train_data[val_indices,]
val_targets <- train_targets[val_indices]
partial_train_data <- train_data[-val_indices,]                      #2
partial_train_targets <- train_targets[-val_indices]
model <- build_model()                                               #3
model %>% fit(partial_train_data, partial_train_targets,             #4
epochs = num_epochs, batch_size = 1, verbose = 0)
results <- model %>% evaluate(val_data, val_targets, verbose = 0)    #5
all_scores <- c(all_scores, results["mae"])
}
head(results)
all_scores
mean(all_scores)
num_epochs <- 500
all_mae_histories <- NULL
for (i in 1:k) {
cat("processing fold #", i, "\n")
val_indices <- which(folds == i, arr.ind = TRUE)              #1
val_data <- train_data[val_indices,]
val_targets <- train_targets[val_indices]
partial_train_data <- train_data[-val_indices,]               #2
partial_train_targets <- train_targets[-val_indices]
model <- build_model()                                        #3
history <- model %>% fit(                                     #4
partial_train_data, partial_train_targets,
validation_data = list(val_data, val_targets),
epochs = num_epochs, batch_size = 1, verbose = 0
)
mae_history <- history$metrics$val_mean_absolute_error
all_mae_histories <- rbind(all_mae_histories, mae_history)
}
average_mae_history <- data.frame(
epoch = seq(1:ncol(all_mae_histories)),
validation_mae = apply(all_mae_histories, 2, mean)
)
library(ggplot2)
ggplot(average_mae_history, aes(x = epoch, y = validation_mae)) + geom_line()
num_epochs <- 500
all_mae_histories <- NULL
for (i in 1:k) {
cat("processing fold #", i, "\n")
val_indices <- which(folds == i, arr.ind = TRUE)              #1 Prepares the validation data: data from partition #k
val_data <- train_data[val_indices,]
val_targets <- train_targets[val_indices]
partial_train_data <- train_data[-val_indices,]               #2 Prepares the training data: data from all other partitions
partial_train_targets <- train_targets[-val_indices]
model <- build_model()                                        #3 Builds the Keras model (already compiled)
print(
system.time( #329.849  36.252 278.699
history <- model %>% fit(
partial_train_data, partial_train_targets,
validation_data = list(val_data, val_targets),
epochs = num_epochs, batch_size = 1, verbose = 0
)
)
)                                                            #4 Trains the model (in silent mode, verbose=0)
mae_history <- history$metrics$val_mean_absolute_error
all_mae_histories <- rbind(all_mae_histories, mae_history)
}
View(history)
num_epochs <- 500
all_mae_histories <- NULL
for (i in 1:k) {
cat("processing fold #", i, "\n")
val_indices <- which(folds == i, arr.ind = TRUE)              #1 Prepares the validation data: data from partition #k
val_data <- train_data[val_indices,]
val_targets <- train_targets[val_indices]
partial_train_data <- train_data[-val_indices,]               #2 Prepares the training data: data from all other partitions
partial_train_targets <- train_targets[-val_indices]
model <- build_model()                                        #3 Builds the Keras model (already compiled)
print(
system.time( #329.849  36.252 278.699
history <- model %>% fit(
partial_train_data, partial_train_targets,
validation_data = list(val_data, val_targets),
epochs = num_epochs, batch_size = 1, verbose = 0
)
)
)                                                            #4 Trains the model (in silent mode, verbose=0)
mae_history <- history$metrics$val_mae
all_mae_histories <- rbind(all_mae_histories, mae_history)
}
average_mae_history <- data.frame(
epoch = seq(1:ncol(all_mae_histories)),
validation_mae = apply(all_mae_histories, 2, mean)
)
library(ggplot2)
ggplot(average_mae_history, aes(x = epoch, y = validation_mae)) + geom_line()
ggplot(average_mae_history, aes(x = epoch, y = validation_mae)) + geom_smooth()
model <- build_model()
model %>% fit(train_data, train_targets,
epochs = 80, batch_size = 16, verbose = 0)
result <- model %>% evaluate(test_data, test_targets)
result
