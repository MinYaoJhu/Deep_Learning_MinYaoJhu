dim(oj.missing)
length(oj.missing)
oj.mean <- apply(OJ.train, 2, mean)
oj.std <- apply(OJ.train, 2, sd)
OJ.train <- scale(OJ.train, center=oj.mean, scale=oj.std)
OJ.test <- scale(OJ.test, center=oj.mean, scale=oj.std)
str(OJ.train)
str(OJ.test)
set.seed(10)
val_indices <- sample(1:nrow(OJ.train), size = 100)
OJ.train_val <- OJ.train[val_indices,]
partial_OJ.train <- OJ.train[-val_indices,]
# class(OJ.train) # to know the
# OJ.test <- data.matrix(OJ.test, rownames.force = NA)
# OJ.train <- data.matrix(OJ.train, rownames.force = NA)
# OJ.train_val <- data.matrix(OJ.train_val, rownames.force = NA)
# partial_OJ.train <- data.matrix(partial_OJ.train, rownames.force = NA)
# matrix and dataframe are different
# matrix need to be the same element (as )
OJ.train_val.label <- OJ.train.label[val_indices]
partial_OJ.train.label <- OJ.train.label[-val_indices]
dim(OJ.train_val)
dim(partial_OJ.train)
class(OJ.train_val)
class(partial_OJ.train)
class(OJ.train_val.label)
class(partial_OJ.train.label)
str(OJ.train_val)
str(partial_OJ.train)
str(OJ.train_val.label)
str(partial_OJ.train.label)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = ncol(OJ.train) ) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
system.time(history <- model %>% fit(
partial_OJ.train,
partial_OJ.train.label,
epochs = 100,
batch_size = 256,
validation_data = list(OJ.train_val, OJ.train_val.label)
))
str(history)
plot(history)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = ncol(OJ.train) ) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
system.time(history <- model %>% fit(
OJ.train,
OJ.train.label,
epochs = 56,
batch_size = 256
))
plot(history)
results <- model %>% evaluate(OJ.test, OJ.test.label)
results
oj.mean <- apply(oj.missing, 2, mean)
oj.std <- apply(oj.missing, 2, sd)
OJ.train <- scale(oj.missing, center=oj.mean, scale=oj.std)
OJ.test <- scale(OJ.test, center=oj.mean, scale=oj.std)
str(OJ.train)
str(OJ.test)
set.seed(10)
val_indices <- sample(1:nrow(OJ.train), size = 100)
OJ.train_val <- OJ.train[val_indices,]
partial_OJ.train <- OJ.train[-val_indices,]
# class(OJ.train) # to know the
# OJ.test <- data.matrix(OJ.test, rownames.force = NA)
# OJ.train <- data.matrix(OJ.train, rownames.force = NA)
# OJ.train_val <- data.matrix(OJ.train_val, rownames.force = NA)
# partial_OJ.train <- data.matrix(partial_OJ.train, rownames.force = NA)
# matrix and dataframe are different
# matrix need to be the same element (as )
OJ.train_val.label <- OJ.train.label[val_indices]
partial_OJ.train.label <- OJ.train.label[-val_indices]
dim(OJ.train_val)
dim(partial_OJ.train)
class(OJ.train_val)
class(partial_OJ.train)
class(OJ.train_val.label)
class(partial_OJ.train.label)
str(OJ.train_val)
str(partial_OJ.train)
str(OJ.train_val.label)
str(partial_OJ.train.label)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = ncol(OJ.train) ) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
system.time(history <- model %>% fit(
partial_OJ.train,
partial_OJ.train.label,
epochs = 100,
batch_size = 256,
validation_data = list(OJ.train_val, OJ.train_val.label),
verbose = 0
))
str(history)
plot(history)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = ncol(OJ.train) ) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
system.time(history <- model %>% fit(
OJ.train,
OJ.train.label,
epochs = 56,
batch_size = 256,
verbose = 0
))
plot(history)
results <- model %>% evaluate(OJ.test, OJ.test.label)
results
library(tidyverse)
library(ISLR)
library(tree)
data(OJ)
#?OJ
head(OJ)
summary(OJ)
OJ %>%
select(StoreID, STORE) %>%
head()
store_cat <- OJ %>%
select(StoreID) %>%
mutate(row=1:nrow(.),data=1) %>%
pivot_wider(id_cols = row, names_from=StoreID, values_from=data, values_fill=0, names_prefix="Store")
head(store_cat)
OJ <- OJ %>%
select(-StoreID, -STORE, -Store7) %>%
cbind(store_cat) %>%
select(-row)
head(OJ)
set.seed(10)
train <- sample(1:nrow(OJ), size = 800)
OJ.train <- OJ[train,]
OJ.test <- OJ[-train,]
str(OJ.test)
str(OJ.train)
tree.OJ=tree(Purchase~.,OJ,subset=train)
summary(tree.OJ)
tree.pred=predict(tree.OJ,OJ.test,type="class")
purchase.test=OJ.test$Purchase
table(tree.pred,purchase.test)
(135+88)/270
1-((135+88)/270)
library(keras)
library(reticulate)
library(tensorflow)
use_condaenv("r-reticulate")
OJ.train.label <- OJ.train %>% select(Purchase) %>% mutate(Purchase=ifelse(Purchase=="CH", 0, 1)) %>% pull(Purchase) # pull take it out as a vector, the same as oj[["purchase"]]
str(OJ.train.label)
OJ.test.label <- OJ.test %>% select(Purchase) %>% mutate(Purchase=ifelse(Purchase=="CH", 0, 1)) %>% pull(Purchase)
str(OJ.test.label)
OJ.train <- OJ.train %>% select(-Purchase)
str(OJ.train)
OJ.test <- OJ.test %>% select(-Purchase)
str(OJ.test)
oj.missing <- OJ.train %>% as.matrix() # must be a matrix for this to work
sum(oj.missing==0) # how many zeros are there already?
dim(oj.missing)
length(oj.missing) # matrixes are really vectors that flow into a 2D space
# put 0 in 10% of the cells
oj.missing[sample(length(oj.missing), size = 0.1*length(oj.missing))] <- 0
sum(oj.missing==0)
dim(oj.missing)
length(oj.missing)
oj.mean <- apply(OJ.train, 2, mean)
oj.std <- apply(OJ.train, 2, sd)
OJ.train <- scale(OJ.train, center=oj.mean, scale=oj.std)
OJ.test <- scale(OJ.test, center=oj.mean, scale=oj.std)
str(OJ.train)
str(OJ.test)
set.seed(10)
val_indices <- sample(1:nrow(OJ.train), size = 100)
OJ.train_val <- OJ.train[val_indices,]
partial_OJ.train <- OJ.train[-val_indices,]
# class(OJ.train) # to know the
# OJ.test <- data.matrix(OJ.test, rownames.force = NA)
# OJ.train <- data.matrix(OJ.train, rownames.force = NA)
# OJ.train_val <- data.matrix(OJ.train_val, rownames.force = NA)
# partial_OJ.train <- data.matrix(partial_OJ.train, rownames.force = NA)
# matrix and dataframe are different
# matrix need to be the same element (as )
OJ.train_val.label <- OJ.train.label[val_indices]
partial_OJ.train.label <- OJ.train.label[-val_indices]
dim(OJ.train_val)
dim(partial_OJ.train)
class(OJ.train_val)
class(partial_OJ.train)
class(OJ.train_val.label)
class(partial_OJ.train.label)
str(OJ.train_val)
str(partial_OJ.train)
str(OJ.train_val.label)
str(partial_OJ.train.label)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = ncol(OJ.train) ) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
system.time(history <- model %>% fit(
partial_OJ.train,
partial_OJ.train.label,
epochs = 100,
batch_size = 256,
validation_data = list(OJ.train_val, OJ.train_val.label),
verbose = 0
))
str(history)
plot(history)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = ncol(OJ.train) ) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
system.time(history <- model %>% fit(
OJ.train,
OJ.train.label,
epochs = 56,
batch_size = 256,
verbose = 0
))
plot(history)
results <- model %>% evaluate(OJ.test, OJ.test.label)
results
oj.mean <- apply(oj.missing, 2, mean)
oj.std <- apply(oj.missing, 2, sd)
OJ.train <- scale(oj.missing, center=oj.mean, scale=oj.std)
OJ.test <- scale(OJ.test, center=oj.mean, scale=oj.std)
str(OJ.train)
str(OJ.test)
set.seed(10)
val_indices <- sample(1:nrow(OJ.train), size = 100)
OJ.train_val <- OJ.train[val_indices,]
partial_OJ.train <- OJ.train[-val_indices,]
# class(OJ.train) # to know the
# OJ.test <- data.matrix(OJ.test, rownames.force = NA)
# OJ.train <- data.matrix(OJ.train, rownames.force = NA)
# OJ.train_val <- data.matrix(OJ.train_val, rownames.force = NA)
# partial_OJ.train <- data.matrix(partial_OJ.train, rownames.force = NA)
# matrix and dataframe are different
# matrix need to be the same element (as )
OJ.train_val.label <- OJ.train.label[val_indices]
partial_OJ.train.label <- OJ.train.label[-val_indices]
dim(OJ.train_val)
dim(partial_OJ.train)
class(OJ.train_val)
class(partial_OJ.train)
class(OJ.train_val.label)
class(partial_OJ.train.label)
str(OJ.train_val)
str(partial_OJ.train)
str(OJ.train_val.label)
str(partial_OJ.train.label)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = ncol(OJ.train) ) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
system.time(history <- model %>% fit(
partial_OJ.train,
partial_OJ.train.label,
epochs = 100,
batch_size = 256,
validation_data = list(OJ.train_val, OJ.train_val.label),
verbose = 0
))
str(history)
plot(history)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = ncol(OJ.train) ) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
system.time(history <- model %>% fit(
OJ.train,
OJ.train.label,
epochs = 40,
batch_size = 256,
verbose = 0
))
plot(history)
results <- model %>% evaluate(OJ.test, OJ.test.label)
results
library(tidyverse)
library(ISLR)
library(tree)
data(OJ)
#?OJ
head(OJ)
summary(OJ)
OJ %>%
select(StoreID, STORE) %>%
head()
store_cat <- OJ %>%
select(StoreID) %>%
mutate(row=1:nrow(.),data=1) %>%
pivot_wider(id_cols = row, names_from=StoreID, values_from=data, values_fill=0, names_prefix="Store")
head(store_cat)
OJ <- OJ %>%
select(-StoreID, -STORE, -Store7) %>%
cbind(store_cat) %>%
select(-row)
head(OJ)
set.seed(10)
train <- sample(1:nrow(OJ), size = 800)
OJ.train <- OJ[train,]
OJ.test <- OJ[-train,]
str(OJ.test)
str(OJ.train)
tree.OJ=tree(Purchase~.,OJ,subset=train)
summary(tree.OJ)
tree.pred=predict(tree.OJ,OJ.test,type="class")
purchase.test=OJ.test$Purchase
table(tree.pred,purchase.test)
(135+88)/270
1-((135+88)/270)
library(keras)
library(reticulate)
library(tensorflow)
use_condaenv("r-reticulate")
OJ.train.label <- OJ.train %>% select(Purchase) %>% mutate(Purchase=ifelse(Purchase=="CH", 0, 1)) %>% pull(Purchase) # pull take it out as a vector, the same as oj[["purchase"]]
str(OJ.train.label)
OJ.test.label <- OJ.test %>% select(Purchase) %>% mutate(Purchase=ifelse(Purchase=="CH", 0, 1)) %>% pull(Purchase)
str(OJ.test.label)
OJ.train <- OJ.train %>% select(-Purchase)
str(OJ.train)
OJ.test <- OJ.test %>% select(-Purchase)
str(OJ.test)
oj.missing <- OJ.train %>% as.matrix() # must be a matrix for this to work
sum(oj.missing==0) # how many zeros are there already?
dim(oj.missing)
length(oj.missing) # matrixes are really vectors that flow into a 2D space
# put 0 in 10% of the cells
oj.missing[sample(length(oj.missing), size = 0.1*length(oj.missing))] <- 0
sum(oj.missing==0)
dim(oj.missing)
length(oj.missing)
oj.mean <- apply(OJ.train, 2, mean)
oj.std <- apply(OJ.train, 2, sd)
OJ.train <- scale(OJ.train, center=oj.mean, scale=oj.std)
OJ.test <- scale(OJ.test, center=oj.mean, scale=oj.std)
str(OJ.train)
str(OJ.test)
set.seed(10)
val_indices <- sample(1:nrow(OJ.train), size = 100)
OJ.train_val <- OJ.train[val_indices,]
partial_OJ.train <- OJ.train[-val_indices,]
# class(OJ.train) # to know the
# OJ.test <- data.matrix(OJ.test, rownames.force = NA)
# OJ.train <- data.matrix(OJ.train, rownames.force = NA)
# OJ.train_val <- data.matrix(OJ.train_val, rownames.force = NA)
# partial_OJ.train <- data.matrix(partial_OJ.train, rownames.force = NA)
# matrix and dataframe are different
# matrix need to be the same element (as )
OJ.train_val.label <- OJ.train.label[val_indices]
partial_OJ.train.label <- OJ.train.label[-val_indices]
dim(OJ.train_val)
dim(partial_OJ.train)
class(OJ.train_val)
class(partial_OJ.train)
class(OJ.train_val.label)
class(partial_OJ.train.label)
str(OJ.train_val)
str(partial_OJ.train)
str(OJ.train_val.label)
str(partial_OJ.train.label)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = ncol(OJ.train) ) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
system.time(history <- model %>% fit(
partial_OJ.train,
partial_OJ.train.label,
epochs = 100,
batch_size = 256,
validation_data = list(OJ.train_val, OJ.train_val.label),
verbose = 0
))
str(history)
plot(history)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = ncol(OJ.train) ) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
system.time(history <- model %>% fit(
OJ.train,
OJ.train.label,
epochs = 60,
batch_size = 256,
verbose = 0
))
plot(history)
results <- model %>% evaluate(OJ.test, OJ.test.label)
results
oj.mean <- apply(oj.missing, 2, mean)
oj.std <- apply(oj.missing, 2, sd)
OJ.train <- scale(oj.missing, center=oj.mean, scale=oj.std)
OJ.test <- scale(OJ.test, center=oj.mean, scale=oj.std)
str(OJ.train)
str(OJ.test)
set.seed(10)
val_indices <- sample(1:nrow(OJ.train), size = 100)
OJ.train_val <- OJ.train[val_indices,]
partial_OJ.train <- OJ.train[-val_indices,]
# class(OJ.train) # to know the
# OJ.test <- data.matrix(OJ.test, rownames.force = NA)
# OJ.train <- data.matrix(OJ.train, rownames.force = NA)
# OJ.train_val <- data.matrix(OJ.train_val, rownames.force = NA)
# partial_OJ.train <- data.matrix(partial_OJ.train, rownames.force = NA)
# matrix and dataframe are different
# matrix need to be the same element (as )
OJ.train_val.label <- OJ.train.label[val_indices]
partial_OJ.train.label <- OJ.train.label[-val_indices]
dim(OJ.train_val)
dim(partial_OJ.train)
class(OJ.train_val)
class(partial_OJ.train)
class(OJ.train_val.label)
class(partial_OJ.train.label)
str(OJ.train_val)
str(partial_OJ.train)
str(OJ.train_val.label)
str(partial_OJ.train.label)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = ncol(OJ.train) ) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
system.time(history <- model %>% fit(
partial_OJ.train,
partial_OJ.train.label,
epochs = 100,
batch_size = 256,
validation_data = list(OJ.train_val, OJ.train_val.label),
verbose = 0
))
str(history)
plot(history)
model <- keras_model_sequential() %>%
layer_dense(units = 16, activation = "relu", input_shape = ncol(OJ.train) ) %>%
layer_dense(units = 16, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = c("accuracy")
)
system.time(history <- model %>% fit(
OJ.train,
OJ.train.label,
epochs = 40,
batch_size = 256,
verbose = 0
))
plot(history)
results <- model %>% evaluate(OJ.test, OJ.test.label)
results
results <- model %>% evaluate(OJ.test, OJ.test.label)
results
