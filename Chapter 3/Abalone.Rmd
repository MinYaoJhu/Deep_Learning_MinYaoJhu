---
title: "Abalone"
author: "Min-Yao"
date: "1/27/2021"
output: html_document
---

```{r}
library(keras)
library(reticulate)
library(tensorflow)
library(tidyverse)
library(janitor)
use_condaenv("r-reticulate")
```

### load data

```{r}
abalone <- readr::read_csv("C:/Users/sandy/rclub/Deep_learning_data/Abalone/abalone.data.csv",col_names = c("sex","length","diameter","height","wholeweight","shockedweight","visceraweight","shellweight","rings"))
dim(abalone)
head(abalone)
str(abalone)
```

### prepare data and label

```{r}
library(ggplot2)
abalone$rings %>% 
  plyr::count() %>%
  ggplot(aes(x, freq)) +
  geom_col()
```

```{r}
abalone_label <- abalone %>% pull(rings)
abalone_label <- as.integer(as.factor(abalone_label)) -1
str(abalone_label)
table(abalone_label)
abalone_data <- abalone %>% mutate(sex=as.integer(as.factor(sex))) %>% 
  select(-c(rings,sex))

set.seed(2)
train <- 1:3133
val <- sample(train,size = 300)

abalone_data_train <- abalone_data[train,]
abalone_data_test <- abalone_data[-train,]
```

#### scale

```{r}
abalone_mean <- apply(abalone_data_train, 2, mean)
abalone_std <- apply(abalone_data_train, 2, sd)

abalone.train <- scale(abalone_data_train, center = abalone_mean, scale = abalone_std)
abalone.test <- scale(abalone_data_test, center = abalone_mean, scale = abalone_std)

str(abalone.train)
str(abalone.test)
```

#### Setting aside a validation set

```{r}
abalone_data_val <- abalone.train[val,]
abalone_data_part <- abalone.train[-val,]

abalone_label_train <- abalone_label[train]
abalone_label_test <- abalone_label[-train]
abalone_label_val <- abalone_label_train[val]
abalone_label_part <- abalone_label_train[-val]
```

```{r}
str(abalone_label_train)
table(abalone_label_train)
abalone_label_train %>% 
  plyr::count() %>%
  ggplot(aes(x, freq)) +
  geom_col()

```

## try different hyperparamaters

```{r}
define_model <- function(nlayers, powerto) {
  
  # input layer
  network <- keras_model_sequential() %>% 
    layer_dense(units = 2^powerto, activation = "relu", input_shape = ncol(abalone.train) ) 
  
  # additional layers
  if (nlayers>1) {
  map(2:nlayers, ~ network %>% 
        layer_dense(units = 2^powerto, activation = "relu")
  )
  }
  
  # output layer
  network %>% 
    layer_dense(units = 28, activation = "softmax")
  
  # compile it
  network %>% compile(
    optimizer = "rmsprop",
    loss = "sparse_categorical_crossentropy",
    metrics = c("accuracy")
  )
  
}
```

```{r}
run_model <- function(network, epochs = 20) {
  network %>% fit(
    abalone_data_part,
    abalone_label_part,
    epochs = epochs,
    batch_size = 64,
    verbose = 0,
    validation_data = list(abalone_data_val, abalone_label_val)
  )
}
```

```{r}
str(abalone_data_part)
str(abalone_label_part)
str(abalone_data_val)
str(abalone_label_val)
```

> 1 layer, units = 64

```{r}
define_model(1,6) %>%
  run_model(100) -> history_1_6

history_1_6 %>%
  plot()
```

> 2 layer, units = 64

```{r}
define_model(2,6) %>%
  run_model(200) -> history_2_6

history_2_6 %>%
  plot()
```

> 3 layer, units = 64

```{r}
define_model(3,6) %>%
  run_model(100) -> history_3_6

history_3_6 %>%
  plot()
```

> 2 layer, units = 128

```{r}
define_model(2,7) %>%
  run_model(100) -> history_2_7

history_2_7 %>%
  plot()
```

> 2 layer, units = 32

```{r}
define_model(2,5) %>%
  run_model(200) -> history_2_5

history_2_5 %>%
  plot()
```
## run the model

### I decided to choose units = 32 & 2 layers to run the model.

```{r}
model <- keras_model_sequential() %>% 
  layer_dense(units = 32, activation = "relu", input_shape = ncol(abalone.train) ) %>% 
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dense(units = 28, activation = "softmax")


model %>% compile(
  optimizer = "rmsprop",
  loss = "sparse_categorical_crossentropy",
  metrics = c("accuracy")
)

system.time(history <- model %>% fit(
  abalone_data_part,
  abalone_label_part,
  epochs = 54,
  batch_size = 64,
  validation_data = list(abalone_data_val, abalone_label_val)
))
```

### View a summary of the model

```{r}
summary(model)
```

```{r}
str(history)
```

```{r}
plot(history)
```
```{r}
model <- keras_model_sequential() %>% 
  layer_dense(units = 32, activation = "relu", input_shape = ncol(abalone.train) ) %>% 
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dense(units = 28, activation = "softmax")


model %>% compile(
  optimizer = "rmsprop",
  loss = "sparse_categorical_crossentropy",
  metrics = c("accuracy")
)

system.time(history <- model %>% fit(
  abalone.train,
  abalone_label_train,
  epochs = 54,
  batch_size = 64
))
```

```{r}
plot(history)
```

```{r}
results <- model %>% evaluate(abalone.test, abalone_label_test)

results
```

```{r}

```

