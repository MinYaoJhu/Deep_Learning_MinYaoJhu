---
title: "Computer Vision: Image Augmentation"
author: "Rick Scavetta"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

# Initialize package
library(keras)

# define the directories:
source("def_dir.R")
```

# Part 1: Data Preparation

## Examine data:

```{r dataGet}

data.frame(Cats = c(length(list.files(train_cats_dir)),
                    length(list.files(validation_cats_dir)),
                    length(list.files(test_cats_dir))),
           Dogs = c(length(list.files(train_dogs_dir)),
                    length(list.files(validation_dogs_dir)),
                    length(list.files(test_dogs_dir))),
           row.names = c("Training", "Validation", "Test")) %>% 
  knitr::kable()


```

## Define and compile model

Using dropout:

- Four sequential conv and max pooling layers
- Flatten layer
- Dropout (new)
- Densly-connected network
- Single binary output

```{r modelDefine}
model <- keras_model_sequential() %>%

  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu", input_shape = c(150, 150, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_flatten() %>%
  
  layer_dropout(rate = 0.5) %>%
  
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4), metrics = c("acc")
)

summary(model)

```

# Data Augmentation

```{r dataGen0}
datagen <- image_data_generator(
  rescale = 1/255,
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE,
  fill_mode = "nearest"
)
```

- Read in the image and resize it
- Converts to an array with shape (150, 150, 3)
- Reshapes it to (1, 150, 150, 3)
- Generates batches of randomly transformed images.

```{r augImages}

fnames <- list.files(train_cats_dir, full.names = TRUE)
img_path <- fnames[[3]]
img <- image_load(img_path, target_size = c(150, 150))
img_array <- image_to_array(img)
img_array <- array_reshape(img_array, c(1, 150, 150, 3))

augmentation_generator <- flow_images_from_data(
  img_array,
  generator = datagen,
  batch_size = 1
)

```

View augmented images

```{r viewImages}

op <- par(mfrow = c(2, 2), pty = "s", mar = c(1, 0, 1, 0))
for (i in 1:4) {
  batch <- generator_next(augmentation_generator)
  plot(as.raster(batch[1,,,]))
}
par(op)

```

Use augmented images:

```{r dataGen1}

datagen <- image_data_generator(
  rescale = 1/255, 
  rotation_range = 40, 
  width_shift_range = 0.2, 
  height_shift_range = 0.2, 
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE
)

```

Note that the validation data shouldnâ€™t be augmented!

```{r dataGen2}
test_datagen <-
  image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory(
  train_dir,
  datagen,
  target_size = c(150, 150),
  batch_size = 32,
  class_mode = "binary"
)

validation_generator <- flow_images_from_directory(
  validation_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 32,
  class_mode = "binary"
)

```

## Train model:

```{r modelTrain}

history <- model %>% fit_generator(
  train_generator,
  steps_per_epoch = 100,
  epochs = 100,
  validation_data = validation_generator,
  validation_steps = 50
)

```

Save model:

```{r saveModel}
model %>% save_model_hdf5("cats_and_dogs_small_2.h5")
```
