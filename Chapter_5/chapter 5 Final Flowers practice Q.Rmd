---
title: "chapter 5 Final Flowers practice Q"
author: "Min-Yao"
date: "5/3/2021"
output: html_document
---

```{r}
library(tidyverse)
library(keras)
library(tensorflow)
tf$compat$v1$disable_eager_execution()
```

```{r}
train_dir <- "C:/Users/sandy/rclub/Deep_learning_data/Final Flowers Course Project Dataset/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers2/train"
validation_dir <- "C:/Users/sandy/rclub/Deep_learning_data/Final Flowers Course Project Dataset/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers2/validation"
test_dir <- "C:/Users/sandy/rclub/Deep_learning_data/Final Flowers Course Project Dataset/Flowers_Dataset_Revised/Flowers_Dataset_Revised/newFlowers2/test"
```

```{r}
train_daisy_dir <- file.path(train_dir, "daisy")
train_dandelion_dir <- file.path(train_dir, "dandelion")
train_rose_dir <- file.path(train_dir, "rose")
train_sunflower_dir <- file.path(train_dir, "sunflower")
train_tulip_dir <- file.path(train_dir, "tulip")

validation_daisy_dir <- file.path(validation_dir, "daisy")
validation_dandelion_dir <- file.path(validation_dir, "dandelion")
validation_rose_dir <- file.path(validation_dir, "rose")
validation_sunflower_dir <- file.path(validation_dir, "sunflower")
validation_tulip_dir <- file.path(validation_dir, "tulip")

test_daisy_dir <- file.path(test_dir, "daisy")
test_dandelion_dir <- file.path(test_dir, "dandelion")
test_rose_dir <- file.path(test_dir, "rose")
test_sunflower_dir <- file.path(test_dir, "sunflower")
test_tulip_dir <- file.path(test_dir, "tulip")
```

```{r}
data.frame(daisy = c(length(list.files(train_daisy_dir)),
                     length(list.files(validation_daisy_dir)),
                     length(list.files(test_daisy_dir))),
           dandelion = c(length(list.files(train_dandelion_dir)),
                         length(list.files(validation_dandelion_dir)),
                         length(list.files(test_dandelion_dir))),
           rose = c(length(list.files(train_rose_dir)),
                    length(list.files(validation_rose_dir)),
                    length(list.files(test_rose_dir))),
           sunflower = c(length(list.files(train_sunflower_dir)),
                         length(list.files(validation_sunflower_dir)),
                         length(list.files(test_sunflower_dir))),
           tulip = c(length(list.files(train_tulip_dir)),
                     length(list.files(validation_tulip_dir)),
                     length(list.files(test_tulip_dir))),
           row.names = c("Training", "Validation", "Test")) %>% 
  knitr::kable()
```

```{r}
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu",
                input_shape = c(150, 150, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_flatten() %>%
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 5, activation = "softmax")
```

```{r}
summary(model)
```

```{r}
model %>% compile(
  optimizer = "rmsprop",
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)
```

```{r}
train_datagen <- image_data_generator(rescale = 1/255)
validation_datagen <- image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory(
  train_dir,
  train_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "categorical"
)

validation_generator <- flow_images_from_directory(
  validation_dir,
  validation_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "categorical"
)
```

```{r}
batch <- generator_next(train_generator)
str(batch)
```

```{r}
system.time(history <- model %>% fit_generator(
  train_generator,
  steps_per_epoch = 100,
  epochs = 30,
  validation_data = validation_generator,
  validation_steps = 50
))
```

```{r}
plot(history)
```

```{r}
model %>% save_model_hdf5("flowers_1.h5")
```

## 5.2.5. Using data augmentation

```{r}
model <- keras_model_sequential() %>%

  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu", input_shape = c(150, 150, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_conv_2d(filters = 128, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  layer_flatten() %>%
  
  layer_dropout(rate = 0.5) %>%
  
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 5, activation = "softmax")

model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(lr = 1e-4), metrics = c("acc")
)

summary(model)
```
### Listing 5.11. Setting up a data augmentation configuration via image_data_generator

```{r}
datagen <- image_data_generator(
  rescale = 1/255,
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE,
  fill_mode = "nearest"
)
```

### Listing 5.12. Displaying some randomly augmented training images

```{r}
fnames <- list.files(train_tulip_dir, full.names = TRUE)
img_path <- fnames[[3]]
img <- image_load(img_path, target_size = c(150, 150))
img_array <- image_to_array(img)
img_array <- array_reshape(img_array, c(1, 150, 150, 3))

augmentation_generator <- flow_images_from_data(
  img_array,
  generator = datagen,
  batch_size = 1
)
```

```{r}
op <- par(mfrow = c(2, 2), pty = "s", mar = c(1, 0, 1, 0))
for (i in 1:4) {
  batch <- generator_next(augmentation_generator)
  plot(as.raster(batch[1,,,]))
}
par(op)
```

### Listing 5.14. Training the convnet using data-augmentation generators

```{r}
datagen <- image_data_generator(
  rescale = 1/255, 
  rotation_range = 40, 
  width_shift_range = 0.2, 
  height_shift_range = 0.2, 
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE
)
```

```{r}
test_datagen <-
  image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory(
  train_dir,
  datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "categorical"
)

validation_generator <- flow_images_from_directory(
  validation_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 20,
  class_mode = "categorical"
)
```

```{r}
system.time(history <- model %>% fit_generator(
  train_generator,
  steps_per_epoch = 100,
  epochs = 100,
  validation_data = validation_generator,
  validation_steps = 50
))
```

```{r}
plot(history)
```

```{r}
model %>% save_model_hdf5("flowers_2.h5")
```

### Listing 5.16. Instantiating the VGG16 convolutional base
```{r}
library(keras)

conv_base <- application_vgg16(
  weights = "imagenet",
  include_top = FALSE,
  input_shape = c(150, 150, 3)
)
```

```{r}
conv_base
```

### Extracting features using the pretrained convolutional base
```{r}
datagen <- image_data_generator(rescale = 1/255)
batch_size <- 20

extract_features <- function(directory, sample_count) {
  features <- array(0, dim = c(sample_count, 4, 4, 512))
  labels <- array(0, dim = c(sample_count))
  generator <- flow_images_from_directory(
    directory = directory,
    generator = datagen,
    target_size = c(150, 150),
    batch_size = batch_size,
    class_mode = "categorical"
  )
  i <- 0
  while(TRUE) {
    batch <- generator_next(generator)
    inputs_batch <- batch[[1]]
    labels_batch <- batch[[2]]
    features_batch <- conv_base %>% predict(inputs_batch)
    index_range <- ((i * batch_size)+1):((i + 1) * batch_size)
    features[index_range,,,] <- features_batch
    labels[index_range] <- labels_batch
    i <- i + 1
    if (i * batch_size >= sample_count)
      break }
  list(
    features = features,
    labels = labels
  ) }


train <- extract_features(train_dir, 2000)
validation <- extract_features(validation_dir, 1000)
test <- extract_features(test_dir, 1000)
```

### Reshape features

```{r}
reshape_features <- function(features) {
  array_reshape(features, dim = c(nrow(features), 4 * 4 * 512))
}
train$features <- reshape_features(train$features)
validation$features <- reshape_features(validation$features)
test$features <- reshape_features(test$features)
```

### Listing 5.18. Defining and training the densely connected classifier
```{r}
# Define model
model <- keras_model_sequential() %>%
  layer_dense(units = 256, activation = "relu",
              input_shape = 4 * 4 * 512) %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 5, activation = "softmax")

# Compile and train
model %>% compile(
  optimizer = optimizer_rmsprop(lr = 2e-5),
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)

system.time(history <- model %>% fit(
  train$features, train$labels,
  epochs = 30,
  batch_size = 20,
  validation_data = list(validation$features, validation$labels)
))
```

```{r}
plot(history)
```

