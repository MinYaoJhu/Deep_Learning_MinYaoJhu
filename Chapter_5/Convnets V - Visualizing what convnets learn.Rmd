---
title: "Computer Vision: Visualizing Cats and Dogs"
author: "Rick Scavetta"
output: html_document
---

# Data sources

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

# Initialize package
library(keras)

# define the directories:
source("def_dir.R")
```

# Obtain a pre-trained networks

```{r getModel}

model <- load_model_hdf5("cats_and_dogs_small_2.h5")
model

```

## view

```{r getIMG}

img_path <- "~/Downloads/cats_and_dogs_small/test/cats/cat.1700.jpg"
img <- image_load(img_path, target_size = c(150, 150))
img_tensor <- image_to_array(img)
img_tensor <- array_reshape(img_tensor, c(1, 150, 150, 3))
img_tensor <- img_tensor / 255

# Preprocesses the image into a 4D tensor
   dim(img_tensor)
   
```

# plot image:

```{r vizIMG}

plot(as.raster(img_tensor[1,,,]))

```

# Instantiating a model from an input tensor and a list of output tensors

```{r act0}

layer_outputs <- lapply(model$layers[1:8], function(layer) layer$output)
activation_model <- keras_model(inputs = model$input, outputs = layer_outputs)

```

# Running the model in predict mode

```{r act1}

activations <- activation_model %>% predict(img_tensor)

```

this is the activation of the first convolution layer for the cat image input:

```{r act2}

first_layer_activation <- activations[[1]]
dim(first_layer_activation)

```

# Function to plot a channel

```{r vizFUN}

plot_channel <- function(channel) {
  rotate <- function(x) t(apply(x, 2, rev))
  image(rotate(channel), axes = FALSE, asp = 1,
        col = terrain.colors(12))
}

```

# Plotting the second channel

```{r viz2}

plot_channel(first_layer_activation[1,,,2])

```

# Visualizing the seventh channel

```{r viz7}

plot_channel(first_layer_activation[1,,,7])

```

# Visualizing every channel in every intermediate activation

```{r vizAll}

image_size <- 58
images_per_row <- 16

for (i in 1:8) {
  layer_activation <- activations[[i]]
  layer_name <- model$layers[[i]]$name
  n_features <- dim(layer_activation)[[4]]
  n_cols <- n_features %/% images_per_row
  png(paste0("cat_activations_", i, "_", layer_name, ".png"),
      width = image_size * images_per_row,
      height = image_size * n_cols)
  op <- par(mfrow = c(n_cols, images_per_row), mai = rep_len(0.02, 4))
  for (col in 0:(n_cols-1)) {
    for (row in 0:(images_per_row-1)) {
      channel_image <- layer_activation[1,,,(col*images_per_row) + row + 1]
      plot_channel(channel_image)
    }
  }
  par(op)
  dev.off() }

```

# Visualizing the Covnnet filters:

# Defining the loss tensor for filter visualization (Listing 5.32)

```{r}

        library(keras)
        model <- application_vgg16(
          weights = "imagenet",
          include_top = FALSE
)
        layer_name <- "block3_conv1"
        filter_index <- 1
        layer_output <- get_layer(model, layer_name)$output
        loss <- k_mean(layer_output[,,,filter_index])

```


# Obtaining the gradient of the loss with regard to the input (Listing 5.33)


The call to k_gradients returns an R list of tensors (of size 1 in this case). Hence, you keep only the first element—which is a tensor.


```{r}

# The call to k_gradients returns an R list of tensors (of size 1 in this case). Hence, you keep only the first element—which is a tensor.
grads <- k_gradients(loss, model$input)[[1]]

```


# Gradient-normalization trick (Listing 5.34)

```{r}

# Add 1e-5 before dividing to avoid accidentally dividing by 0
grads <- grads / (k_sqrt(k_mean(k_square(grads))) + 1e-5)

```

# Fetching output values given input values (Listing 5.35)

```{r}

iterate <- k_function(list(model$input), list(loss, grads))
c(loss_value, grads_value) %<-%
    iterate(list(array(0, dim = c(1, 150, 150, 3))))

```

# Loss maximization via stochastic gradient descent (Listing 5.36 )

```{r}
# Starts from a gray image with some noise
input_img_data <- array(runif(150 * 150 * 3), dim = c(1, 150, 150, 3)) * 20 + 128

# Runs gradient ascent for 40 step
step <- 1
for (i in 1:40) { 
  # Computes the loss value and gradient value
  c(loss_value, grads_value) %<-% iterate(list(input_img_data))
  
  # Adjusts the input image in the direction that maximizes the loss
  input_img_data <- input_img_data + (grads_value * step)  
}

```

# Utility function to convert a tensor into a valid image (Listing 5.37)

```{r}
deprocess_image <- function(x) {
  dms <- dim(x)

    # Normalizes the tensor: centers on 0., ensures that std is 0.1
  x <- x - mean(x)
  x <- x / (sd(x) + 1e-5)
  x <- x * 0.1
  
# Clips to [0, 1]
    x <- x + 0.5
  x <- pmax(0, pmin(x, 1))
  
  # Returns with the original image dimensions
  array(x, dim = dms)
}
```

# Function to generate filter visualizations

```{r}
generate_pattern <- function(layer_name, filter_index, size = 150) {
  
  # Builds a loss function that maximizes the activation of the nth filter of the layer under consideration
  layer_output <- model$get_layer(layer_name)$output
  loss <- k_mean(layer_output[,,,filter_index])
  
  # Computes the gradient of the input picture with regard to this loss
  grads <- k_gradients(loss, model$input)[[1]]
  
  # Normalization trick: normalizes the gradient
  grads <- grads / (k_sqrt(k_mean(k_square(grads))) + 1e-5)
  
  # Returns the loss and grads given the input picture
  iterate <- k_function(list(model$input), list(loss, grads))
  
  # Starts from a gray image with some noise
  input_img_data <-
  array(runif(size * size * 3), dim = c(1, size, size, 3)) * 20 + 128
# Runs gradient ascent for 40 steps
  step <- 1
for (i in 1:40) {
  c(loss_value, grads_value) %<-% iterate(list(input_img_data))
  input_img_data <- input_img_data + (grads_value * step)
}

img <- input_img_data[1,,,]
   deprocess_image(img)
 }

```


# Generating a grid of all filter response patterns in a layer (Listing 5.39)

```{r}
library(grid)
library(gridExtra)
dir.create("vgg_filters")
for (layer_name in c("block1_conv1", "block2_conv1",
                     "block3_conv1", "block4_conv1")) {
size <- 140
  png(paste0("vgg_filters/", layer_name, ".png"),
      width = 8 * size, height = 8 * size)
  grobs <- list()
  for (i in 0:7) {
    for (j in 0:7) {
      pattern <- generate_pattern(layer_name, i + (j*8) + 1, size = size)
      grob <- rasterGrob(pattern,
                         width = unit(0.9, "npc"),
                   height = unit(0.9, "npc"))
grobs[[length(grobs)+1]] <- grob
} }
  grid.arrange(grobs = grobs, ncol = 8)
dev.off()
}

```


