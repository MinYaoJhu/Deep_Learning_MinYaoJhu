---
title: "Computer Vision: Visualizing Cats and Dogs"
author: "Rick Scavetta"
output: html_document
---

# Data sources

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

# Initialize package
library(keras)

# define the directories:
source("def_dir.R")
```

# Obtain a pre-trained networks

```{r getModel}

model <- load_model_hdf5("cats_and_dogs_small_2.h5")
model

```

## view

```{r getIMG}

img_path <- "~/Downloads/cats_and_dogs_small/test/cats/cat.1700.jpg"
img <- image_load(img_path, target_size = c(150, 150))
img_tensor <- image_to_array(img)
img_tensor <- array_reshape(img_tensor, c(1, 150, 150, 3))
img_tensor <- img_tensor / 255

# Preprocesses the image into a 4D tensor
   dim(img_tensor)
   
```

# plot image:

```{r vizIMG}

plot(as.raster(img_tensor[1,,,]))

```

# Instantiating a model from an input tensor and a list of output tensors

```{r act0}

layer_outputs <- lapply(model$layers[1:8], function(layer) layer$output)
activation_model <- keras_model(inputs = model$input, outputs = layer_outputs)

```

# Running the model in predict mode

```{r act1}

activations <- activation_model %>% predict(img_tensor)

```

this is the activation of the first convolution layer for the cat image input:

```{r act2}

first_layer_activation <- activations[[1]]
dim(first_layer_activation)

```

# Function to plot a channel

```{r vizFUN}

plot_channel <- function(channel) {
  rotate <- function(x) t(apply(x, 2, rev))
  image(rotate(channel), axes = FALSE, asp = 1,
        col = terrain.colors(12))
}

```

# Plotting the second channel

```{r viz2}

plot_channel(first_layer_activation[1,,,2])

```

# Visualizing the seventh channel

```{r viz7}

plot_channel(first_layer_activation[1,,,7])

```

# Visualizing every channel in every intermediate activation

```{r vizAll}

image_size <- 58
images_per_row <- 16

for (i in 1:8) {
  layer_activation <- activations[[i]]
  layer_name <- model$layers[[i]]$name
  n_features <- dim(layer_activation)[[4]]
  n_cols <- n_features %/% images_per_row
  png(paste0("cat_activations_", i, "_", layer_name, ".png"),
      width = image_size * images_per_row,
      height = image_size * n_cols)
  op <- par(mfrow = c(n_cols, images_per_row), mai = rep_len(0.02, 4))
  for (col in 0:(n_cols-1)) {
    for (row in 0:(images_per_row-1)) {
      channel_image <- layer_activation[1,,,(col*images_per_row) + row + 1]
      plot_channel(channel_image)
    }
  }
  par(op)
  dev.off() }

```

# Visualizing the Covnnet filters:

```{r}

Defining the loss tensor for filter visualization
        library(keras)
        model <- application_vgg16(
          weights = "imagenet",
          include_top = FALSE
)
        layer_name <- "block3_conv1"
        filter_index <- 1
        layer_output <- get_layer(model, layer_name)$output
        loss <- k_mean(layer_output[,,,filter_index])

```


# Obtaining the gradient of the loss with regard to the input


The call to k_gradients returns an R list of tensors (of size 1 in this case). Hence, you keep only the first elementâ€”which is a tensor.


```{r}

grads <- k_gradients(loss, model$input)[[1]]

```


# Gradient-normalization trick

```{r}

grads <- grads / (k_sqrt(k_mean(k_square(grads))) + 1e-5)

```

# Fetching output values given input values

```{r}

iterate <- k_function(list(model$input), list(loss, grads))
c(loss_value, grads_value) %<-%
    iterate(list(array(0, dim = c(1, 150, 150, 3))))

```

# Loss maximization via stochastic gradient descent (Listing 5.36 )

```{r}
# Starts from a gray image with some noise
input_img_data <- array(runif(150 * 150 * 3), dim = c(1, 150, 150, 3)) * 20 + 128

step <- 1

# Runs gradient ascent for 40 step
for (i in 1:40) { 
  # Computes the loss value and gradient value
  c(loss_value, grads_value) %<-% iterate(list(input_img_data))
  
  # Adjusts the input image in the direction that maximizes the loss
  input_img_data <- input_img_data + (grads_value * step)  
}

```

# Utility function to convert a tensor into a valid image (Listing 5.37)

```{r}
deprocess_image <- function(x) {
  dms <- dim(x)
  x <- x - mean(x)
  x <- x / (sd(x) + 1e-5)
  x <- x * 0.1
  x <- x + 0.5
  x <- pmax(0, pmin(x, 1))
  array(x, dim = dms)
}
```



# Generating a grid of all filter response patterns in a layer (Listing 5.39)

```{r}
library(grid)
library(gridExtra)
dir.create("vgg_filters")
for (layer_name in c("block1_conv1", "block2_conv1",
                     "block3_conv1", "block4_conv1")) {
size <- 140
  png(paste0("vgg_filters/", layer_name, ".png"),
      width = 8 * size, height = 8 * size)
  grobs <- list()
  for (i in 0:7) {
    for (j in 0:7) {
      pattern <- generate_pattern(layer_name, i + (j*8) + 1, size = size)
      grob <- rasterGrob(pattern,
                         width = unit(0.9, "npc"),
                   height = unit(0.9, "npc"))
grobs[[length(grobs)+1]] <- grob
} }
  grid.arrange(grobs = grobs, ncol = 8)
dev.off()
}

```


